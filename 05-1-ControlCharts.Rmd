# Control charts {#controlcharts}

## Statistical distributions

The primary distinction between run and control charts is that the latter uses parametric statistics to increase the number of properties of a data-defined process that you can monitor. If a particular statistical distribution---such as normal, binomial, or Poisson---matches the process you wish to measure, you gain a great deal more power to find insights and monitor change than with a line or run chart.  

Parametric distributions are a *useful fiction*---no data will follow an idealized distribution, but as long as it's close, it provides some useful shortcuts that allow SPC charts to work *in practice*.   

### Common distributions and their ranges

There are [hundreds of statistical distributions](http://vosesoftware.com/knowledgebase/whitepapers/pdf/ebookdistributions.pdf) DO WE NEED TO WORRY ABOUT COPYRIGHT? MAYBE LINK TO https://en.wikipedia.org/wiki/List_of_probability_distributions?, but only a handful are commonly used in SPC work:  

| Data Type | Distribution | Range | Skew | Example | SPC chart |
| --------- | ------------ | ----- | ---- | ------- | --------- |
| *Discrete* | Binomial | 0, $N$ | Any | Bundle compliance percentage | *p*, *np* | 
| | Poisson | 0, $\infty$ | Right | Infections per 1,000 line days | *u*, *c* | 
| | Geometric | 0, $\infty$ | Right | Number of surgeries between complications | *g* | 
| *Continuous* | Normal | $-\infty$, $\infty$ | None | Patient wait times | *I*, $\bar{x}$, EWMA, CUSUM | 
| | Weibull | 0, $\infty$ | Right | Time between antibiotic doses | *t* | 


### Mean and variance

When control charts use the mean to create the center line, they use the arithmetic mean. Rather than using the $\bar{x}$ abbreviation, these mean values are usually named for the type of chart (*u*, *p*, etc.) to emphasize the use of control limits that are not based on the normal distribution. The variance used to calculate the control limits differs by distribution.   

### What happens when you get the mean-variance relationship wrong

Although control charts can sometimes work when you misspecify the mean-variance relationship (they are "robust" to some assumption violations), you won't know unless you explore the differences in implications between the data as-is and that same data transformed to become more in line with the appropriate or expected distribution.  

For example, if you use the usual normal distribution control limits (an *I* chart) on gamma-distributed data, you get something like this:  

```{r skewy, fig.height=3.5}
# Create some fake gamma-distributed process data
set.seed(3)
df2 = data.frame(x = seq(1:120), y = rgamma(120, shape = 3, rate = 0.8)) 

# Create plot object
exp_nat_var_cc_plot = ggplot(df2, aes(x, y)) + 
  ylim(-3, 11) +
  geom_hline(aes(yintercept=mean(y)), color="gray", size=1) +
  geom_hline(aes(yintercept=mean(y)+(3*sd(y))), color="red") +
  geom_hline(aes(yintercept=mean(y)-(3*sd(y))), color="red") +
  geom_ribbon(aes(ymin = mean(y)-(2*sd(y)), ymax = mean(y)-(1*sd(y))), alpha = 0.2) +
  geom_ribbon(aes(ymin = mean(y)+(1*sd(y)), ymax = mean(y)+(2*sd(y))), alpha = 0.2) +
  xlab("Subgroup") + 
  ylab("Value") +
  geom_line() + geom_point() + 
  theme_bw()

# Marginal plot
ggMarginal(exp_nat_var_cc_plot, margins="y", type = "histogram", binwidth=1)
```

Clearly something is weird when very few points go below one standard deviation, and none go below two. And do the points above the upper control limit represent *real* anomalous data points, or are they the result of an improper mean-variance relationship? 

Using a Box-Cox transformation to make the distribution more symmetrical, we can see that those seemingly out-of-control points are actually well within both control limits, and the variation we see is more in line with (statistical) expectation. 

```{r unskewy, fig.height=3.5}
# Box-Cox tansformation 
bob = data.frame(MASS::boxcox(df2$y ~ 1, lambda=seq(-10, 10, 0.05), plotit=F))
bobmax = bob[which.max(bob[,2]),1]

# Adjustment to make plotting cleaner
df2$y2 = (df2$y ^ bobmax) 

# Create plot object
exp_xform_nat_var_cc_plot = ggplot(df2, aes(x, y2)) + 
  ylim(0.5, 2.25) +
  geom_hline(aes(yintercept=mean(y2)), color="gray", size=1) +
  geom_hline(aes(yintercept=mean(y2)+(3*sd(y2))), color="red") +
  geom_hline(aes(yintercept=mean(y2)-(3*sd(y2))), color="red") +
  geom_ribbon(aes(ymin = mean(y2)-(2*sd(y2)), ymax = mean(y2)-(1*sd(y2))), alpha = 0.2) +
  geom_ribbon(aes(ymin = mean(y2)+(1*sd(y2)), ymax = mean(y2)+(2*sd(y2))), alpha = 0.2) +
  xlab("Subgroup") + 
  ylab("Transformed Value") +
  geom_line() + geom_point() +
  theme_bw()

# Marginal plot
ggMarginal(exp_xform_nat_var_cc_plot, margins="y", type = "histogram", binwidth=0.125)
```

The main drawback is that you now have a chart of essentially uninterptable values---but that's better than assuming a normal distribution will be just fine and being unnecessarily alarmed by false positive signals, wasting time and resources searching for a special cause that doesn't exist.    

So should you always transform when your data doesn't meet the usual distributions common in control charts? Not necessarily. For more information, see, for example, *The arcsine is asinine* [@WartonHui2016] and *Do not log-transform count data* [@OharaKotze2010]. DO YOU HAVE A LINK FOR THESE OR A CITATION? Consult a statistician if you aren't sure how to proceed.  

### What *is* the distribution?

There are R packages and functions to evaluate your data and show what distribution(s) are most consistent with it. This does *not* tell you that your data does follow a given distribution, only that it's consistent with it. Further analysis is usually required; consult a statistician when you're uncertain.  

As an example, we can use the gamma-distrubted data created above to show how it works.  

```{r fitdist}
library(fitdistrplus)
expo_dist = descdist(df2$y, boot = 1000)
```

<br>  

A Cullen and Frey graph compares your data set and bootstrapped replications of it to common theoretical distributions. You compare your data (blue dot) and the replications (orange open circles) to locations within the plot that represent theoretical distributions. For example, if the blue dot were at or near the \* at the top left and more or less surrounded by the orange open circles, it would imply that our data are most consistent with a normal distribution. Other common distributions are represented in the graph by points (e.g., the exponential distribution), area (e.g., the beta distribution), or by lines (e.g., the gamma distribution).  

This chart shows us that our data (blue dot) and simuations from that data (orange open circles) are most consistent with a gamma distribution and a perhaps a lognormal distribution. Using `qqPlot` lets us evaluate these two options directly:    

```{r qqplot, fig.width=3, fig.height=3}
# Create objects of the two most-likely distributions
logno = fitdistr(df2$y, "lognormal")
gammo = fitdistr(df2$y, "gamma")

# The car package has a good quantile-quantile plot function
library(car)
qqPlot(df2$y, "lnorm", meanlog = logno$estimate[1], sdlog = logno$estimate[2], id=FALSE);
qqPlot(df2$y, "gamma", shape = gammo$estimate[1], rate = gammo$estimate[2],id=FALSE)
```

Although both distributions fall within the confidence limits (dashed lines), the points fit to a gamma distribution (right) DOUBLE-CHECK ORIENTATION are closer to the line of best fit.  

This is expected, since we created this data from a gamma distribution, but in practice, we don't know what distribution the data comes from---so using this process can help you determine which distributions are most consistent with the data, and help you model and plot it appropriately.  


## Which control chart should I use? {#whichcontrolchart}

The following flow chart can help you determine which kind of control chart you might want to use. More details and formulas for each control chart type are provided in the next few chapters.   

```{r which_flow, echo = FALSE, fig.align = "center"}
knitr::include_graphics("images/control_chart_flowchart.png")
```


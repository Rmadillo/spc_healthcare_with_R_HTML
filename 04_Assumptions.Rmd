---
title: "04_Assumptions"
output: pdf_document
---

# Step 2: Checking Assumptions {-}

There are three main assumptions that must be met for a SPC chart to be meaningful. 

1. We assume that the data does not contain a trend. 
2. We assume that the data is independent. 
3. We assume that the data is not autocorrelated. 


## Trending

In the previous step, you already completed a trend test: you looked at the line chart and decided if it was trending or not. You can tell by eye: does it look like it's trending over a large span of the time series? If so, then it probably is trending.

The Mann-Kendall trend test is often used as well. It is a non-parametric test that can determine whether the series contains a monotonic trend, linear or not. The null hypothesis being tested is that the data does not contain a trend. We will implement this test in R below. A caveat is that when sample size is low (n < 20) this test is not useful/accurate.

Let's run the Mann-Kendall trend test on Rachel's data.

```{r}
# Use the trend package's Mann-Kendall trend test
trend::mk.test(rachel_data$infections)
```

The test gives us a p-value of 0.9389, thus we cannot reject the null hypothesis. We can conclude that the data does not contain a trend. This agrees with our visual test, but keep in mind that we still have a low sample size (n = 24). 

Because trends can be an indication of special cause variation in a stable process, standard control limits don't make sense around long-trending data, and calculation of center lines and control limits will be incorrect. **Thus, any SPC tests for special causes other than trending will *also* be invalid over long-trending data.** An alternative is to use a run chart with a median slope instead, e.g., via quantile regression. You can generally wait until the process has settled to a new, stable mean and reset the central line accordingly. For a sustained or continuous trend, you can difference the data (create a new dataset by subtracting the value at time *t* from the value at time *t+1*) to remove the trend or use regression residuals to show deviations from the trend. However, either approach can make the run chart harder to interpret. Perhaps a better idea is use quantile regression to obtain the median line, which allows you to keep the data on the original scale. 



## Independence / Autocorrelation

Independence and autocorrelation are two important, related terms. Independence generally means that the value of the data will not change due to other variables or previous data points, ex. rolling a fair die and flipping a coin. The value that the die lands on should not be affected by the coin flip nor the previous value of the die. Correlation is the tendency for one variable to increase or decrease as a different variable increases. Autocorrelation is a variable that correlates with itself lagged or leading in time, ex. if it rained yesterday, it will be more likely to rain today. If variables are independent, then they do not have any correlation.

For either run charts or control charts, the data points must be independent for the guidelines to be effective. The first test of that is conceptual---do you expect that one value in this series will influence a subsequent value? For example, the incidence of some hospital-acquired infections can be the result of previous infections. Suppose one happens at the end of March and another happens at the start of April in the same unit, caused by the same organism---you might suspect that the monthly values would not be independent. 

After considering the context, a second way to assess independence is by calculating the autocorrelation function (acf) for the time series. 

The `acf` function provides a graphical summary of the autocorrelation function, with each data point correlated with a value at increasing lagged distances from itself. Each correlation is plotted as a spike; spikes that go above or below the dashed line suggest that significant positive or negative autocorrelation, respectively, occurs at that lag (at the 95% confidence level). If all spikes occur inside those limits, it's safe to assume that there is no autocorrelation. If only one or perhaps two spikes exceed the limits slightly, it could be due simply to chance. Clear patterns seen in the acf plot can indicate autocorrelation even when the values do not exceed the limits. 

Autocorrelation values over 0.50 generally indicate problems, as do patterns in the autocorrelation function. However, *any* significant autocorrelation should be considered carefully relative to the cost of potential false positive or false negative signals. Autocorrelation means that the run chart and control chart interpretation guidelines will be wrong.

For control charts, autocorrelated data will result in control limits that are too small. Data with seasonality (predictable up-and-down patterns) or cycles (irregular up-and-down patterns) will have control limits that are too large. There are diagnostic plots and patterns that help identify each, but the best test is "what does it look like?" If the trend seems to be going up and down, and the control limits don't, it's probably wrong.

```{r acfplotsfortable, include=FALSE}
# png("images/ac.png", width = 6, height = 4, units = "in", res = 600)
# autoplot(acf(mb_ts))
# dev.off()
# 
# png("images/no_ac.png", width = 6, height = 4, units = "in", res = 600)
# autoplot(acf(df_ts, plot = FALSE))
# dev.off()
```

For convenience of comparison, here are autocorrelated and non-autocorrelated data already shown above, shown here side-by-side.  

| Example autocorrelated data | Example non-autocorrelated data |
| ------ | ------ |
| ![](images/ac.png) | ![](images/no_ac.png) |

When data are autocorrelated, control limits will be *too small*---and thus an increase in *false* signals of special causes should be expected. In addition, none of the tests for special cause variation remain valid.    

Sometimes, autocorrelation can be removed by changing the sampling or metric's time step: for example, you generally wouldn't expect hospital acquired infection rates in one quarter to influence those in the subsequent quarter.  

It can also be sometimes removed or abated with differencing, although doing so hurts interpretability of the resulting run or control chart.  

```{r diffing, fig.height=3}
# Take the fourth lag to difference the beer data
beer_diff = diff(beer, lag = 4)

# Plot the resulting autocorrelation function
autoplot(acf(beer_diff, plot = FALSE))
```

If have autocorrelated data, and you aren't willing to difference the data or can't change the sampling rate or time step, you shouldn't use either run or control charts, and instead use a standard line chart. If you must have limits to help guide decision-making, you'll need a more advanced technique, such as a Generalized Additive Mixed Model (GAMM) or time series models such as ARIMA. It's probably best to work with a statistician if you need to do this.    




Now we will inspect Rachel's dataset for both independence and autocorrelation. 

First we should consider the context. This is CLABSI (central line associated blood stream infection) data. Does the infection of one patient influence the infection of the next patient? Ideally, we would hope not, but infections can spread. Let's now see what the autocorrelation function (acf) has to say.

Using the `forecast` package's `ggtsdisplay` provides a view of the time series along with the acf and spectral frequency (where frequency is the reciprocal of the time period). Significant autocorrelation is present if there are bars that transgress the blue dashed line in the ACF plot (bottom left). Cycles or seasonality are present if you see a clear peak (or peaks) in the spectrum plot (bottom right).  

<br>  

```{r ts_eda}
# ggtsdisplay requires the input to be a time series
df_ts <- ts(rachel_data$infections)

# Plot series, acf plot, and spectal plot
ggtsdisplay(df_ts, plot.type = "spectrum") 
```

These plots show that there is no autocorrelation or seasonality/cyclical patterns in the data: there are no obvious patterns nor any bars that cross the blue lines in the acf plot (bottom left), and  there are no peaks in the spectral density plot (bottom right). This means that all three assumptions are valid for Rachel's data and she can move on to the next step, creating a run chart. 

Before you move on, however, these are very important concepts. Take a minute to think over the following questions: 

*** 
1. Why isn't the Mann-Kendall trend test always useful? 
2. What is independence and why is it important? 
3. How can you recognize autocorrelation in control charts? 
4. What happens if you make conclusions from a control chart where these assumptions are not valid?
***

**Understanding your data is a fundamental prerequisite of SPC work. Do *not* move on to SPC work until you have explored your data using the techniques demonstrated above and fully understand whether the data are suitable for SPC tools.**

If you still feel uncomfortable with these principles, check out [Chapter 8](#timedep) {SKP: update link} for more information and examples, including what these plots can look like when you have time-dependent or otherwise autocorrelated data. 

> "But what if I understand everything and my data doesn't upheld these assumptions?"

When you do have such data, you cannot use standard SPC tools. Generalized additive models (GAMs or GAMMs) can be useful alternatives; see [Chapter 13](#useful) for some good initial references. {SKP: update link}

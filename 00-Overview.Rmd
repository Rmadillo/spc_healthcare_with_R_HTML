# Signal, noise, and statisical process control {#SPC}

People are really good at finding patterns that aren't real. 

Every process has natural variation---*noise*---included as an inherent part of that process. True signals emerge only when you have properly characterized that variation. Statistical process control (SPC) charts---run charts and control charts---help you characterize and identify non-random patterns that suggest your process has changed.  

Control charts are meant to help you identify departures from a **stable** process. Run charts help you monitor any sort of metric, process, or time series data. Each uses a set of guidelines to help you make decisions on whether a process has changed or not.  

In many cases, a run chart may be all you need. In *all* cases, you should start with a run chart. If---and only if---you need to characterize the limits of natural variation in a stable process, you can move on to using a control chart.   

In addition, *never* rely on a table or year-to-date (YTD) comparisons to evaluate process performance. These approaches ignore the foundational concept of process control: that natural, "common-cause" variation is an essential part of the process, and you can't see natural variation in a table or in YTD comparisons. Tables or YTD values can supplement run or control charts, but should never be used without them.  

Above all, remember that the decisions you make in constructing SPC charts *will* impact the interpretation of the results. Bad charts can make for bad decisions. 

## Stability

It’s going to take time and resources to track new KPIs (collecting the data, developing the dashboards, etc), so you should be very clear on what the definition of “stability” is, and make sure these KPIs are actually useful in tracking that stability.

In many cases when folks talk about “stability” they mean “constant” and think of their stability KPI as trying to keep their previous KPI at some fixed value or achieve some fixed target. However, in the case of units which are getting many more FTEs and in the case of patient access that is facing increasing patient demand and constrained hospital capacity, we do not expect the situation to be constant over time.

We expect the call center performance to improve (in terms of percent of calls answered in under 2 minutes) and access to suffer (in terms of percent of new visit seen within 2 weeks of calling for an appointment). So what does “stable” mean in a changing environment?

My definition of “stability” would be that the system is responding as we would expect to the changing environment and that the system is robust to adverse surprises from the environment. **KPIs should be specifically designed to track this.** Essentially any KPI should track whether the process or system is stable and robust, rather than focusing strictly on the outcome as defined by previous KPIs. I can explain with two examples.

In the past, the primary KPI for the call center has been percent of calls answered within 2 minutes. So, what would a “stable” call center look like as they add FTEs and the old KPI improves over time? Perhaps it would be that the performance of the various teams within the call center become more similar (e.g., decreased variability across teams). Maybe it could be the frequency of adverse events (e.g., people waiting longer than X minutes) staying below some threshold – similar to a “downtime” KPI used to track the stability of computer systems. Maybe it could be something along the lines of the percent change in the old KPI tracking the percent change in FTEs (though we know this relationship is non-linear). The point is, we know performance as previously defined will be improving in the call center, but we still want to track “stability” in the face of these improvements.

The current KPI for access is the percent of new visit patients who have to wait less than or equal to 14 days between the day they call to schedule their appointment and the date of their appointment. We expect this will be decreasing over the next year as demand is expected to rise at a faster rate than capacity for new visits. So, what would a stable system look like in this case? Right now, the thought is that the KPI could be something like the change in access that we would predict to occur based on actual changes in demand and capacity (prediction model developed from past data) compared to the actual change in access. In other words, is the system responding as it has in the past? The problem is that if actual changes deviate largely from predicted changes, we don’t know if that’s caused by an incorrect assumption in the prediction model or lack of stability in the actual system.  We’re currently brainstorming other metrics.

In both of these cases, stability can not be defined simply as lack of change in the previous performance metrics. 

You should make sure the KPIs for stability are properly designed from the outset before we spend large amounts of resources to develop and track them. 

Another part will depend on the purpose of the KPI.  If, as I think is the case for access specifically,  the purpose is to help us better understand access and to serve as a warning system for when we need to dig deeper into both the model and the data, this should do fairly well.  If the goal is to serve as a warning system to trigger corrective  management actions (which I don’t think it is), then we would want a level of accuracy in the predictions that I’m not sure we’ll be able to achieve at this point. 

